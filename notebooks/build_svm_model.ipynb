{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "from course_utils import trainTest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from models import evaluate_accuracy\n",
    "import models\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import pickler\n",
    "import extract_metadata\n",
    "import join_data as jd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ../data/feature_matrix_100.svmlight and ../data/case_ids.p\n"
     ]
    }
   ],
   "source": [
    "case_data_dir = '../data'\n",
    "CASE_DATA_FILENAME = 'merged_caselevel_data.csv'\n",
    "cases_df = extract_metadata.extract_metadata(case_data_dir+'/'+CASE_DATA_FILENAME)\n",
    "num_shards = 1340\n",
    "X, case_ids, y=jd.load_data(case_data_dir+'/feature_matrix_100.svmlight',\n",
    "              case_data_dir+'/case_ids.p',\n",
    "              cases_df, \n",
    "              case_data_dir+'/docvec_text',\n",
    "              num_opinion_shards=num_shards,\n",
    "              min_required_count=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##TODO: \n",
    "- try TF-IDF True or false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def subsample(X,y,case_ids, sample_pct):\n",
    "    '''\n",
    "    Take a random sub-sample of the rows in your data set.  NOTE: to keep it predictable, this is seeded.\n",
    "    Args:\n",
    "        X: feature matrix\n",
    "        y: label array\n",
    "        case_ids: list of case ids\n",
    "        sample_pct: float between 0 and 1, determines what fraction of the data you want to keep. \n",
    "        \n",
    "    Returns X,y, and case_ids, but filtered down to a random sample\n",
    "    '''\n",
    "    case_ids2 = np.array(case_ids)\n",
    "    assert X.shape[0]==len(y), \"X and y are not the same length\"\n",
    "    assert len(case_ids2)==len(y), \"case_ids and y are not the same length\"\n",
    "    sample_size = int(sample_pct*len(y))\n",
    "    np.random.seed(10)\n",
    "    \n",
    "    #Get random sub-sample of row indexes\n",
    "    sample_indexes = sorted(np.random.choice(range(len(y)), size=sample_size,replace=False))\n",
    "    return X[sample_indexes],y[sample_indexes],list(case_ids2[sample_indexes])\n",
    "    \n",
    "X,y,case_ids = subsample(X,y,case_ids,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_test_split(X,y, ordered_case_ids,pct_train):\n",
    "    train_rows = int(pct_train*len(y))\n",
    "    y_train = np.array(y[:train_rows])\n",
    "    y_test = np.array(y[train_rows:])\n",
    "    X_train = X[:train_rows]\n",
    "    X_test = X[train_rows:]\n",
    "    case_ids_train = ordered_case_ids[:train_rows]\n",
    "    case_ids_test = ordered_case_ids[train_rows:]\n",
    "    return X_train,y_train,case_ids_train,X_test,y_test,case_ids_test\n",
    "\n",
    "X_train,y_train,case_ids_train,X_test,y_test,case_ids_test = train_test_split(X,y,case_ids,0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1159, 23534)\n",
      "(387, 23534)\n",
      "(1159,)\n",
      "(387,)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print y_train.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Baseline Model\n",
    "The base line majority classifier model to beat is 54% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t \t pred\n",
      "true \t \t 1 \t 2 \t 3\n",
      "\t 1 \t 214 \t 0 \t 0\n",
      "\t 2 \t 62 \t 0 \t 0\n",
      "\t 3 \t 111 \t 0 \t 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.55297157622739013"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(models)\n",
    "mclf = models.MajorityClassifier()\n",
    "mclf.fit(X_train,y_train)\n",
    "\n",
    "evaluate_accuracy(y_test,mclf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Out-of-the-Box SVM\n",
    "Gets accuracy of 39%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l1', random_state=0, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC(penalty='l1',random_state=0, dual=False)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56581329195758989"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t \t pred\n",
      "true \t \t 1 \t 2 \t 3\n",
      "\t 1 \t 5061 \t 89 \t 501\n",
      "\t 2 \t 329 \t 1253 \t 258\n",
      "\t 3 \t 682 \t 97 \t 3329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.83136477282524357"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t \t pred\n",
      "true \t \t 1 \t 2 \t 3\n",
      "\t 1 \t 1643 \t 106 \t 405\n",
      "\t 2 \t 337 \t 134 \t 156\n",
      "\t 3 \t 579 \t 96 \t 411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.56581329195758989"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Optimized SVM\n",
    "Accuracy is truly horrendous: 40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimizeSVM(X_train, y_train, reg_min_log10=-2, reg_max_log10=2, regularization_type='l1'):\n",
    "    '''\n",
    "    Creates an SVM classifier trained on the given data with an optimized C parameter.\n",
    "    Args:\n",
    "      X_train: A dataframe on which to train the features\n",
    "      y_train: A dataframe on which to evaluate the training data\n",
    "      reg_min_log10: log base 10 of the low end of the regularization parameter range.  -2 means 10^-2\n",
    "      reg_max_log10: log base 10 of the high end of the regularization parameter range.  2 means 10^2\n",
    "    Returns:\n",
    "      A fitted SVM classifier.\n",
    "    '''\n",
    "    \n",
    "    model_to_set = LinearSVC(penalty=regularization_type,random_state=0, dual=False)\n",
    "    # consider broadening the param_grid to include different SVM kernels and degrees.  See:\n",
    "    # http://stackoverflow.com/questions/12632992/gridsearch-for-an-estimator-inside-a-onevsrestclassifier\n",
    "    #param_grid = {'C': [10**i for i in range(-reg_min_log10,reg_max_log10)] + [1e30]}\n",
    "    param_grid = {'C':[1]}\n",
    "    model_tuning = GridSearchCV(model_to_set, scoring='f1_weighted',param_grid=param_grid)\n",
    "    \n",
    "    model_tuning.fit(X_train, y_train)\n",
    "    print 'best C param for SVM classifier:', model_tuning.best_params_['C']\n",
    "    print 'best_score: ', model_tuning.best_score_\n",
    "        \n",
    "    return model_tuning.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best C param for SVM classifier: 1\n",
      "best_score:  0.476915211796\n"
     ]
    }
   ],
   "source": [
    "svm_opt = optimizeSVM(X_train,y_train,-4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55038759689922478"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_opt.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t \t pred\n",
      "true \t \t 1 \t 2 \t 3\n",
      "\t 1 \t 175 \t 51 \t 72\n",
      "\t 2 \t 5 \t 0 \t 1\n",
      "\t 3 \t 34 \t 11 \t 38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.55038759689922478"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(svm_opt.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimizeLogistic(X_train, y_train, reg_min_log10=-2, reg_max_log10=2,regularization_type='l1'):\n",
    "    '''\n",
    "    Creates an SVM classifier trained on the given data with an optimized C parameter.\n",
    "    Args:\n",
    "      X_train: A dataframe on which to train the features\n",
    "      y_train: A dataframe on which to evaluate the training data\n",
    "      score_func: Scoring function.  Dizzying options here.  Consider:\n",
    "          metrics.accuracy_score\n",
    "          metrics.f1_score\n",
    "    Returns:\n",
    "      A fitted SVM classifier.\n",
    "    '''\n",
    "    \n",
    "    model_to_set = LogisticRegression(penalty=regularization_type)\n",
    "    param_grid = {'C': [10**i for i in range(-reg_min_log10,reg_max_log10)] + [1e30]}\n",
    "    model_tuning = GridSearchCV(model_to_set, param_grid=param_grid,\n",
    "                             scoring='f1_weighted')\n",
    "    \n",
    "    model_tuning.fit(X_train, y_train)\n",
    "    print 'best C param for LR classifier:', model_tuning.best_params_['C']\n",
    "    print 'best params: ', model_tuning.best_params_\n",
    "    print 'best_score: ', model_tuning.best_score_\n",
    "        \n",
    "    return model_tuning.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best C param for LR classifier: 1e+30\n",
      "best params:  {'C': 1e+30}\n",
      "best_score:  0.47046562865\n"
     ]
    }
   ],
   "source": [
    "logit_opt = optimizeLogistic(X_train,y_train,reg_min_log10=-4, reg_max_log10=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47545219638242892"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_opt.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t \t pred\n",
      "true \t \t 1 \t 2 \t 3\n",
      "\t 1 \t 143 \t 35 \t 73\n",
      "\t 2 \t 23 \t 12 \t 9\n",
      "\t 3 \t 48 \t 15 \t 29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47545219638242892"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(logit_opt.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
