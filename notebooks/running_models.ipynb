{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_DATA_DIR = '/Users/205341/Documents/git/machine-learning/appeals/data'\n",
    "OUTPUT_DATA_DIR = '/Users/205341/Documents/git/machine-learning/appeals/data'\n",
    "\n",
    "RESULT_PATH = '../results/model_results.pkl'\n",
    "NUM_OPINION_SHARDS = 100 #1340\n",
    "MIN_REQUIRED_COUNT = 20 #150\n",
    "USE_TFIDF = True\n",
    "\n",
    "# Model params\n",
    "TRAIN_PCT = 0.75\n",
    "REG_MIN_LOG10 = -2\n",
    "REG_MAX_LOG10 = 2\n",
    "SCORING = 'f1_weighted'\n",
    "# NOTE: this will be too slow to run locally if feature reduction is enabled\n",
    "FEATURE_REDUCTION_TYPE = None # TODO try 'chi2' or l1svc\n",
    "\n",
    "X, case_ids, y = jd.load_data(INPUT_DATA_DIR, OUTPUT_DATA_DIR,\n",
    "                              NUM_OPINION_SHARDS, MIN_REQUIRED_COUNT, USE_TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and scoring models...\n",
      "\n",
      "Fitting New Model\n",
      "Model: baseline\n",
      "Feature Matrix Info:\n",
      "  Number of cases 1403\n",
      "  Number of features 11009\n",
      "Training percentage 0.75\n",
      "Scoring used: None\n",
      "Splitting data into training and testing...\n",
      "Total time: 0.014053106308\n",
      "Training Accuracy\n",
      "\t \t pred\n",
      "true \t \t 1 \t 2 \t 3\n",
      "\t 1 \t 466 \t 0 \t 0\n",
      "\t 2 \t 175 \t 0 \t 0\n",
      "\t 3 \t 411 \t 0 \t 0\n",
      "Percent Accuracy: 44.297%\n",
      "Testing Accuracy\n",
      "\t \t pred\n",
      "true \t \t 1 \t 2 \t 3\n",
      "\t 1 \t 189 \t 0 \t 0\n",
      "\t 2 \t 65 \t 0 \t 0\n",
      "\t 3 \t 97 \t 0 \t 0\n",
      "Percent Accuracy: 53.846%\n",
      "\n",
      "Fitting New Model\n",
      "Model: logistic\n",
      "Feature Matrix Info:\n",
      "  Number of cases 1403\n",
      "  Number of features 11009\n",
      "Training percentage 0.75\n",
      "Scoring used: f1_weighted\n",
      "Regularization bounded between 10^(-2) and 10^(2):\n",
      "Splitting data into training and testing...\n",
      "Running Model Pipeline...\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  15 | elapsed:    0.7s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.3s finished\n",
      "/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Complete!\n",
      "\n",
      "best estimator: Pipeline(steps=[('classifier', LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0))])\n",
      "best params: {'classifier__C': 10}\n",
      "best score from that estimator: 0.487924144812\n",
      "Total time: 1.9694018364\n",
      "Training Accuracy\n",
      "\t \t pred\n",
      "true \t \t 1 \t 2 \t 3\n",
      "\t 1 \t 464 \t 0 \t 2\n",
      "\t 2 \t 1 \t 173 \t 1\n",
      "\t 3 \t 1 \t 0 \t 410\n",
      "Percent Accuracy: 99.525%\n",
      "Testing Accuracy\n",
      "\t \t pred\n",
      "true \t \t 1 \t 2 \t 3\n",
      "\t 1 \t 116 \t 3 \t 70\n",
      "\t 2 \t 27 \t 5 \t 33\n",
      "\t 3 \t 44 \t 2 \t 51\n",
      "Percent Accuracy: 49.003%\n",
      "\n",
      "Fitting New Model\n",
      "Model: svm\n",
      "Feature Matrix Info:\n",
      "  Number of cases 1403\n",
      "  Number of features 11009\n",
      "Training percentage 0.75\n",
      "Scoring used: f1_weighted\n",
      "Regularization bounded between 10^(-2) and 10^(2):\n",
      "Splitting data into training and testing...\n",
      "Running Model Pipeline...\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  15 | elapsed:    0.8s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    5.2s finished\n",
      "/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Complete!\n",
      "\n",
      "best estimator: Pipeline(steps=[('classifier', LinearSVC(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
      "     verbose=0))])\n",
      "best params: {'classifier__C': 1}\n",
      "best score from that estimator: 0.491340864088\n",
      "Total time: 5.6084549427\n",
      "Training Accuracy\n",
      "\t \t pred\n",
      "true \t \t 1 \t 2 \t 3\n",
      "\t 1 \t 464 \t 0 \t 2\n",
      "\t 2 \t 0 \t 174 \t 1\n",
      "\t 3 \t 1 \t 0 \t 410\n",
      "Percent Accuracy: 99.620%\n",
      "Testing Accuracy\n",
      "\t \t pred\n",
      "true \t \t 1 \t 2 \t 3\n",
      "\t 1 \t 114 \t 4 \t 71\n",
      "\t 2 \t 28 \t 5 \t 32\n",
      "\t 3 \t 42 \t 2 \t 53\n",
      "Percent Accuracy: 49.003%\n",
      "\n",
      "Fitting New Model\n",
      "Model: naive_bayes\n",
      "Feature Matrix Info:\n",
      "  Number of cases 1403\n",
      "  Number of features 11009\n",
      "Training percentage 0.75\n",
      "Scoring used: f1_weighted\n",
      "Regularization bounded between 10^(-2) and 10^(2):\n",
      "Splitting data into training and testing...\n",
      "Running Model Pipeline...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting Complete!\n",
      "\n",
      "best estimator: Pipeline(steps=[('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "best params: {}\n",
      "best score from that estimator: 0.442301053632\n",
      "Total time: 0.297289133072\n",
      "Training Accuracy\n",
      "\t \t pred\n",
      "true \t \t 1 \t 2 \t 3\n",
      "\t 1 \t 422 \t 0 \t 44\n",
      "\t 2 \t 108 \t 0 \t 67\n",
      "\t 3 \t 104 \t 0 \t 307\n",
      "Percent Accuracy: 69.297%\n",
      "Testing Accuracy\n",
      "\t \t pred\n",
      "true \t \t 1 \t 2 \t 3\n",
      "\t 1 \t 138 \t 0 \t 51\n",
      "\t 2 \t 46 \t 0 \t 19\n",
      "\t 3 \t 51 \t 0 \t 46\n",
      "Percent Accuracy: 52.422%\n",
      "\n",
      "Fitting New Model\n",
      "Model: bernoulli_bayes\n",
      "Feature Matrix Info:\n",
      "  Number of cases 1403\n",
      "  Number of features 11009\n",
      "Training percentage 0.75\n",
      "Scoring used: f1_weighted\n",
      "Regularization bounded between 10^(-2) and 10^(2):\n",
      "Splitting data into training and testing...\n",
      "Running Model Pipeline...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   6 | elapsed:    0.1s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s finished\n",
      "/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Complete!\n",
      "\n",
      "best estimator: Pipeline(steps=[('classifier', BernoulliNB(alpha=1.0, binarize=0.01, class_prior=None, fit_prior=True))])\n",
      "best params: {'classifier__binarize': 0.01}\n",
      "best score from that estimator: 0.495269607738\n",
      "Total time: 0.580715894699\n",
      "Training Accuracy\n",
      "\t \t pred\n",
      "true \t \t 1 \t 2 \t 3\n",
      "\t 1 \t 363 \t 20 \t 83\n",
      "\t 2 \t 31 \t 124 \t 20\n",
      "\t 3 \t 66 \t 4 \t 341\n",
      "Percent Accuracy: 78.707%\n",
      "Testing Accuracy\n",
      "\t \t pred\n",
      "true \t \t 1 \t 2 \t 3\n",
      "\t 1 \t 107 \t 28 \t 54\n",
      "\t 2 \t 21 \t 26 \t 18\n",
      "\t 3 \t 28 \t 21 \t 48\n",
      "Percent Accuracy: 51.567%\n"
     ]
    }
   ],
   "source": [
    "# TODO write a loop for all of the params\n",
    "print 'Training and scoring models...'\n",
    "train_and_score_model(X, y, case_ids, 'baseline', train_pct=TRAIN_PCT, \n",
    "                      reg_min_log10=None, reg_max_log10=None, scoring=None, feature_reduction_type=None,\n",
    "                      result_path=RESULT_PATH)\n",
    "train_and_score_model(X, y, case_ids, 'logistic', train_pct=TRAIN_PCT,\n",
    "                      reg_min_log10=REG_MIN_LOG10, reg_max_log10=REG_MAX_LOG10, scoring=SCORING, feature_reduction_type=FEATURE_REDUCTION_TYPE,\n",
    "                      result_path=RESULT_PATH)\n",
    "train_and_score_model(X, y, case_ids, 'svm', train_pct=TRAIN_PCT,\n",
    "                      reg_min_log10=REG_MIN_LOG10, reg_max_log10=REG_MAX_LOG10, scoring=SCORING, feature_reduction_type=FEATURE_REDUCTION_TYPE,\n",
    "                      result_path=RESULT_PATH)\n",
    "train_and_score_model(X, y, case_ids, 'naive_bayes', train_pct=TRAIN_PCT,\n",
    "                      reg_min_log10=REG_MIN_LOG10, reg_max_log10=REG_MAX_LOG10, scoring=SCORING, feature_reduction_type=FEATURE_REDUCTION_TYPE,\n",
    "                      result_path=RESULT_PATH)\n",
    "train_and_score_model(X, y, case_ids, 'bernoulli_bayes', train_pct=TRAIN_PCT,\n",
    "                      reg_min_log10=REG_MIN_LOG10, reg_max_log10=REG_MAX_LOG10, scoring=SCORING, feature_reduction_type=FEATURE_REDUCTION_TYPE,\n",
    "                      result_path=RESULT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_and_score_model(X, y, case_ids, model,\n",
    "                          train_pct, reg_min_log10, reg_max_log10, scoring, feature_reduction_type,\n",
    "                          result_path):\n",
    "\n",
    "    '''\n",
    "    Train and score a model\n",
    "    Args:\n",
    "        X,y,case_ids - your data.  X is a matrix, y is an array, case_ids is a list\n",
    "        model: string.  So far either 'baseline', 'logistic', or 'svm'\n",
    "        train_pct: float between 0 and 1.  Fraction of your subsample to use as training.\n",
    "        reg_min_log10, reg_max_log10: integers.  The low and high of your grid search for regularization parameter.\n",
    "        scoring: scoring method\n",
    "        feature_reduction_type: Either 'chi2', 'l1svc', or None.\n",
    "\n",
    "    Returns:\n",
    "        Model score\n",
    "\n",
    "    Prints out: Model score and confusion matrix\n",
    "    '''\n",
    "    start_time = time.time()\n",
    "\n",
    "    print '\\nFitting New Model'\n",
    "    print 'Model:', model\n",
    "    print 'Feature Matrix Info:'\n",
    "    print '  Number of cases', X.shape[0]\n",
    "    print '  Number of features', X.shape[1]\n",
    "    print 'Training percentage', train_pct\n",
    "    print 'Scoring used:', scoring\n",
    "    if reg_min_log10 and reg_max_log10:\n",
    "        print 'Regularization bounded between 10^(%d) and 10^(%d):' % (\n",
    "            reg_min_log10, reg_max_log10)\n",
    "\n",
    "    print 'Splitting data into training and testing...'\n",
    "    X_train, y_train, case_ids_train, X_test, y_test, case_ids_test = train_test_split(X, y, case_ids, train_pct)\n",
    "\n",
    "    pipeline_steps = list()\n",
    "    param_grid = dict()\n",
    "\n",
    "    # Feature reduction step\n",
    "    if feature_reduction_type == 'chi2':\n",
    "        pipeline_steps.append(('feature_reduction', SelectFpr(chi2)))\n",
    "        param_grid['feature_reduction__alpha'] = [0.6, 0.8, 1.0] # TODO check where this ends up, expand around where it lands\n",
    "    elif feature_reduction_type == 'l1svc':\n",
    "        # TODO we can modify the stopping point with 'tol'\n",
    "        pipeline_steps.append(('feature_reduction', LinearSVC(penalty=\"l1\", dual=False)))\n",
    "        param_grid['feature_reduction__C'] = [10**i for i in range(reg_min_log10, reg_max_log10 + 1)] # TODO check where this ends up, expand around where it lands\n",
    "\n",
    "    if model == 'baseline':\n",
    "        # TODO This isn't taking part in feature reduction!\n",
    "        fitted_model = MajorityClassifier()\n",
    "        fitted_model.fit(X_train, y_train)\n",
    "    else:\n",
    "        if model == 'svm':\n",
    "            # random_state=0 so it always has the same seed so we get deterministic results.\n",
    "            # Using dual=False b.c. there are lots of features.\n",
    "            classifier = LinearSVC(penalty='l2', random_state=0, dual=False)\n",
    "#            param_grid['classifier__penalty'] = ['l1', 'l2'] # TODO this makes it redoc slow\n",
    "            param_grid['classifier__C'] = [10**i for i in range(reg_min_log10, reg_max_log10 + 1)]\n",
    "        elif model == 'logistic':\n",
    "            classifier = LogisticRegression(penalty='l2')\n",
    "#            param_grid['classifier__penalty'] = ['l1', 'l2'] # TODO this makes it redonc slow\n",
    "            param_grid['classifier__C'] = [10**i for i in range(reg_min_log10, reg_max_log10 + 1)]\n",
    "        elif model == 'naive_bayes':\n",
    "            # TODO why fit_prior? why not?\n",
    "            classifier = MultinomialNB(fit_prior=True)\n",
    "        elif model == 'bernoulli_bayes':\n",
    "            # TODO trying aribtrary thresholds for binarize b.c. i'm assuming we've TF-IDF'd the data already.\n",
    "            param_grid['classifier__binarize'] = [0.01, 0.1]\n",
    "            classifier = BernoulliNB()\n",
    "        else:\n",
    "            print \"ERROR: model unknown\"\n",
    "            return\n",
    "        pipeline_steps.append(('classifier', classifier))\n",
    "\n",
    "        print 'Running Model Pipeline...'\n",
    "        fitted_model = GridSearchCV(Pipeline(pipeline_steps), scoring=scoring, param_grid=param_grid, \n",
    "                                    verbose=1, n_jobs=-1)\n",
    "        fitted_model.fit(X_train, y_train)\n",
    "\n",
    "        print 'Fitting Complete!\\n'\n",
    "        print 'DIR', fitted_model.dir()\n",
    "        print 'grid scores:',fitted_model.grid_scores_\n",
    "        print 'best estimator:', fitted_model.best_estimator_\n",
    "        print 'best params:', fitted_model.best_params_\n",
    "        print 'best score from that estimator:', fitted_model.best_score_\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print 'Total time:', total_time\n",
    "\n",
    "    print \"Training Accuracy\"\n",
    "    train_accuracy = print_accuracy_info(fitted_model.predict(X_train), y_train)\n",
    "    print \"Testing Accuracy\"\n",
    "    test_accuracy = print_accuracy_info(fitted_model.predict(X_test), y_test)\n",
    "\n",
    "    #log parameters and output\n",
    "    log_results(locals(),result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_results(locals_dict,log_path):\n",
    "    '''\n",
    "    Save model parameters, accuracy, and training time as a dict and append to pickled log file\n",
    "    Args:\n",
    "        locals_dict: dictionary of variables in parent function\n",
    "        log_path: path to pickled log file\n",
    "        \n",
    "    Returns: None\n",
    "    '''\n",
    "    log_items = locals_dict\n",
    "    \n",
    "    #read results log\n",
    "    try:\n",
    "        log = pickle.load(open( log_path, \"rb\" ))\n",
    "    except:\n",
    "        print \"Log file doesn't exist.  Creating from scratch.\"\n",
    "        log = []\n",
    "    \n",
    "    #Remove raw data from local_vars_dict\n",
    "    for key in ('X','y','case_ids','X_train', 'y_train', 'case_ids_train', 'X_test', 'y_test', 'case_ids_test'):\n",
    "        if key in log_items:\n",
    "            del log_items[key]\n",
    "\n",
    "    print \"FITTED MODEL\",log_items['fitted_model']\n",
    "\n",
    "    #convert start timestamp to datetime\n",
    "    log_items['start_date_time']=time.ctime(int(log_items['start_time']))\n",
    "    \n",
    "    #append result\n",
    "    log.append(log_items)\n",
    "    \n",
    "    #write to results log\n",
    "    pickle.dump( log, open( log_path, \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting New Model\n",
      "Model: logistic\n",
      "Feature Matrix Info:\n",
      "  Number of cases 1403\n",
      "  Number of features 11009\n",
      "Training percentage 0.75\n",
      "Scoring used: f1_weighted\n",
      "Regularization bounded between 10^(-2) and 10^(2):\n",
      "Splitting data into training and testing...\n",
      "Running Model Pipeline...\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  15 | elapsed:    0.6s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.1s finished\n",
      "/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/205341/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Complete!\n",
      "\n",
      "DIR"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-050d835cde6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train_and_score_model(X, y, case_ids, 'logistic', train_pct=TRAIN_PCT,\n\u001b[1;32m      2\u001b[0m                       \u001b[0mreg_min_log10\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mREG_MIN_LOG10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_max_log10\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mREG_MAX_LOG10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSCORING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_reduction_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFEATURE_REDUCTION_TYPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                       result_path=RESULT_PATH)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-2607b2857cc3>\u001b[0m in \u001b[0;36mtrain_and_score_model\u001b[0;34m(X, y, case_ids, model, train_pct, reg_min_log10, reg_max_log10, scoring, feature_reduction_type, result_path)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'Fitting Complete!\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'DIR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitted_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'grid scores:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfitted_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'best estimator:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitted_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'dir'"
     ]
    }
   ],
   "source": [
    "train_and_score_model(X, y, case_ids, 'logistic', train_pct=TRAIN_PCT,\n",
    "                      reg_min_log10=REG_MIN_LOG10, reg_max_log10=REG_MAX_LOG10, scoring=SCORING, feature_reduction_type=FEATURE_REDUCTION_TYPE,\n",
    "                      result_path=RESULT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
