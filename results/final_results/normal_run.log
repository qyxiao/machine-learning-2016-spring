Experiment: 20150511-205329.min_required_count.100.chi2.accuracy.
Data parameters:
  Number of opinion shards: 1340
  Minimum required count: 100
  Using TF-IDF: True
Data loaded from /scratch/akp258/ml_output_data/feature_matrix.svmlight.shards.1340.mincount.100.tfidf , /scratch/akp258/ml_output_data/case_ids.shards.p.1340.mincount.100.tfidf , /scratch/akp258/ml_output_data/cases_df.shards.p.1340.mincount.100.tfidf , /scratch/akp258/ml_output_data/ngram_ids.shards.p.1340.mincount.100
Total time spent building data: 13.0604679585
Reading in ngram dictionary test_data/filtered_vocab_map.p.num_shards.508.cutoff.50
Loading ngram dictionary with 45011 keys
Training and scoring models...

Fitting New Model
Model: baseline
Feature Matrix Info:
  Number of cases 15466
  Number of features 23534
Training percentage 0.75
Scoring used: None
Splitting data into training and testing...
Total time: 0.0847358703613
	 	 pred
true 	 	 1 	 2 	 3
	 1 	 5651 	 0 	 0
	 2 	 1840 	 0 	 0
	 3 	 4108 	 0 	 0
Percent Accuracy: 48.720%
Training Accuracy 0.48719717217
	 	 pred
true 	 	 1 	 2 	 3
	 1 	 2154 	 0 	 0
	 2 	 627 	 0 	 0
	 3 	 1086 	 0 	 0
Percent Accuracy: 55.702%
Testing Accuracy 0.55702094647
Log file doesn't exist.  Creating from scratch.

Fitting New Model
Model: naive_bayes
Feature Matrix Info:
  Number of cases 15466
  Number of features 23534
Training percentage 0.75
Scoring used: accuracy
Regularization bounded between 10^(-2) and 10^(2):
Splitting data into training and testing...
Running Model Pipeline...
Fitting 3 folds for each of 4 candidates, totalling 12 fits
[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    1.3s
[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    3.7s finished
Fitting Complete!

best estimator: Pipeline(steps=[('feature_reduction', SelectFpr(alpha=0.8, score_func=<function chi2 at 0x2b33604b81b8>)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])
best params: {'feature_reduction__alpha': 0.8}
best score from that estimator: 0.54056384171
Label 0:
  say evid
  licens
  analog
  decre affirm
  liabil
  certain
  NOT FOUND
  NOT FOUND
  day
  secur
Label 1:
  ownership control
  satisfactori
  deal
  instead
  day
  secur
  decre affirm
  NOT FOUND
  requir
  analog
Label 2:
  instead
  ownership control
  said
  decre affirm
  day
  NOT FOUND
  begin
  analog
  fact appel
  secur
Total time: 4.31085896492
	 	 pred
true 	 	 1 	 2 	 3
	 1 	 4029 	 123 	 1499
	 2 	 652 	 519 	 669
	 3 	 1436 	 88 	 2584
Percent Accuracy: 61.488%
Training Accuracy 0.614880593155
	 	 pred
true 	 	 1 	 2 	 3
	 1 	 1545 	 31 	 578
	 2 	 312 	 63 	 252
	 3 	 537 	 25 	 524
Percent Accuracy: 55.133%
Testing Accuracy 0.551331781743

Fitting New Model
Model: bernoulli_bayes
Feature Matrix Info:
  Number of cases 15466
  Number of features 23534
Training percentage 0.75
Scoring used: accuracy
Regularization bounded between 10^(-2) and 10^(2):
Splitting data into training and testing...
Running Model Pipeline...
Fitting 3 folds for each of 8 candidates, totalling 24 fits
[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.9s
[Parallel(n_jobs=-1)]: Done  11 out of  24 | elapsed:    3.2s remaining:    3.8s
[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    5.9s finished
Fitting Complete!

best estimator: Pipeline(steps=[('feature_reduction', SelectFpr(alpha=0.8, score_func=<function chi2 at 0x2b33604b81b8>)), ('classifier', BernoulliNB(alpha=1.0, binarize=0.1, class_prior=None, fit_prior=True))])
best params: {'classifier__binarize': 0.1, 'feature_reduction__alpha': 0.8}
best score from that estimator: 0.538839555134
Label 0:
  begin
  connect sale
  certain
  NOT FOUND
  say evid
  liabil
  analog
  secur
  NOT FOUND
  day
Label 1:
  ownership control
  challeng
  satisfactori
  remedi
  ct ed said
  instead
  day
  NOT FOUND
  requir
  analog
Label 2:
  convert
  neb
  rule court
  secur
  satisfi
  NOT FOUND
  day
  begin
  analog
  fact appel
Total time: 6.30032801628
	 	 pred
true 	 	 1 	 2 	 3
	 1 	 3652 	 555 	 1444
	 2 	 333 	 1121 	 386
	 3 	 1070 	 389 	 2649
Percent Accuracy: 63.988%
Training Accuracy 0.639882748513
	 	 pred
true 	 	 1 	 2 	 3
	 1 	 1356 	 187 	 611
	 2 	 281 	 148 	 198
	 3 	 454 	 138 	 494
Percent Accuracy: 51.668%
Testing Accuracy 0.516679596587

Fitting New Model
Model: logistic
Feature Matrix Info:
  Number of cases 15466
  Number of features 23534
Training percentage 0.75
Scoring used: accuracy
Regularization bounded between 10^(-2) and 10^(2):
Splitting data into training and testing...
Running Model Pipeline...
Fitting 3 folds for each of 20 candidates, totalling 60 fits
[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.8s
[Parallel(n_jobs=-1)]: Done  22 out of  60 | elapsed:    6.8s remaining:   11.7s
[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   25.5s finished
Fitting Complete!

best estimator: Pipeline(steps=[('feature_reduction', SelectFpr(alpha=1.0, score_func=<function chi2 at 0x2b33604b81b8>)), ('classifier', LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr',
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0))])
best params: {'classifier__C': 1, 'feature_reduction__alpha': 1.0}
best score from that estimator: 0.559013708078
Label 0:
  NOT FOUND
  sentenc
  dividend
  custodi
  identif
  appeal
  invent
  affirm
  indict
  convict
Label 1:
  respect
  bank
  fault
  remand
  appeal dismiss
  count
  damag
  contract
  parti
  curiam
Label 2:
  decis tax court
  decis tax
  custodian
  deduct
  new trial
  remedi
  NOT FOUND
  revers remand
  revers
  remand
Total time: 28.956592083
	 	 pred
true 	 	 1 	 2 	 3
	 1 	 4842 	 124 	 685
	 2 	 617 	 854 	 369
	 3 	 1216 	 116 	 2776
Percent Accuracy: 73.041%
Training Accuracy 0.730407793775
	 	 pred
true 	 	 1 	 2 	 3
	 1 	 1751 	 61 	 342
	 2 	 401 	 81 	 145
	 3 	 677 	 47 	 362
Percent Accuracy: 56.736%
Testing Accuracy 0.567364882338

Fitting New Model
Model: svm
Feature Matrix Info:
  Number of cases 15466
  Number of features 23534
Training percentage 0.75
Scoring used: accuracy
Regularization bounded between 10^(-2) and 10^(2):
Splitting data into training and testing...
Running Model Pipeline...
Fitting 3 folds for each of 20 candidates, totalling 60 fits
[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    1.1s
[Parallel(n_jobs=-1)]: Done  22 out of  60 | elapsed:    8.6s remaining:   14.8s
[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.3min finished
Fitting Complete!

best estimator: Pipeline(steps=[('feature_reduction', SelectFpr(alpha=0.8, score_func=<function chi2 at 0x2b33604b81b8>)), ('classifier', LinearSVC(C=0.1, class_weight=None, dual=False, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,
     verbose=0))])
best params: {'classifier__C': 0.1, 'feature_reduction__alpha': 0.8}
best score from that estimator: 0.557979136132
Label 0:
  NOT FOUND
  NOT FOUND
  fault
  lodg
  save
  know
  fact suffici
  new
  conclud
  clear
Label 1:
  ct ed ann cas
  ct ed
  answer
  assign error
  favor
  confess
  NOT FOUND
  requir
  NOT FOUND
  ct ed said
Label 2:
  NOT FOUND
  avail
  award damag
  reach
  consequ
  consumm
  recommend
  proper
  error instruct
  assign error
Total time: 81.076335907
	 	 pred
true 	 	 1 	 2 	 3
	 1 	 4597 	 160 	 894
	 2 	 729 	 709 	 402
	 3 	 1549 	 145 	 2414
Percent Accuracy: 66.557%
Training Accuracy 0.665574618502
	 	 pred
true 	 	 1 	 2 	 3
	 1 	 1796 	 38 	 320
	 2 	 425 	 64 	 138
	 3 	 703 	 38 	 345
Percent Accuracy: 57.021%
Testing Accuracy 0.570209464701
Stratified model results saved to /scratch/akp258/ml_results/model_results.pkl.20150511-205329.min_required_count.100.chi2.accuracy..csv
