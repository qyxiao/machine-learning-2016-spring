Experiment: 20150510-213959.min_required_count.100.chi2.accuracy.
Data parameters:
  Number of opinion shards: 1340
  Minimum required count: 100
  Using TF-IDF: True
Constructing data from scratch...
Reading input data from from: /scratch/akp258/ml_input_data
Parsing opinion shard files...
Computing total n-gram counts...
Writing n-gram counts to disk...
Filtering n-grams...
coded_feature_names:  None
Building sparse matrix...
Running tfidf transformation...
shape:  (15466, 23534)
number of cases 15466
Writing input data to disk...
Feature matrix saved as /scratch/akp258/ml_output_data/feature_matrix.svmlight.shards.1340.mincount.100.tfidf
Case IDs saved as /scratch/akp258/ml_output_data/case_ids.shards.p.1340.mincount.100.tfidf
NGram IDs saved as /scratch/akp258/ml_output_data/ngram_ids.shards.p.1340.mincount.100
Total time spent building data: 649.850712061
Reading in ngram dictionary test_data/filtered_vocab_map.p.num_shards.508.cutoff.50
Loading ngram dictionary with 45011 keys
Training and scoring models...

Fitting New Model
Model: baseline
Feature Matrix Info:
  Number of cases 15466
  Number of features 23534
Training percentage 0.75
Scoring used: None
Splitting data into training and testing...
Total time: 0.150948047638
	 	 pred
true 	 	 1 	 3
	 1 	 5651 	 0
	 3 	 4108 	 0
Percent Accuracy: 57.906%
Training Accuracy 0.579055231069
	 	 pred
true 	 	 1 	 2 	 3
	 1 	 2154 	 0 	 0
	 2 	 627 	 0 	 0
	 3 	 1086 	 0 	 0
Percent Accuracy: 55.702%
Testing Accuracy 0.55702094647
Log file doesn't exist.  Creating from scratch.

Fitting New Model
Model: naive_bayes
Feature Matrix Info:
  Number of cases 15466
  Number of features 23534
Training percentage 0.75
Scoring used: accuracy
Regularization bounded between 10^(-2) and 10^(2):
Splitting data into training and testing...
Running Model Pipeline...
Fitting 3 folds for each of 4 candidates, totalling 12 fits
[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.7s
[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    2.6s finished
Fitting Complete!

best estimator: Pipeline(steps=[('feature_reduction', SelectFpr(alpha=1.0, score_func=<function chi2 at 0x2b42b12aa2a8>)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])
best params: {'feature_reduction__alpha': 1.0}
best score from that estimator: 0.63551593401
Label 0:
  act
  district
  appel
  defend
  case
  board
  plaintiff
  NOT FOUND
  NOT FOUND
  court
Total time: 6.35993003845
	 	 pred
true 	 	 1 	 3
	 1 	 4248 	 1403
	 3 	 1487 	 2621
Percent Accuracy: 70.386%
Training Accuracy 0.703863100728
	 	 pred
true 	 	 1 	 2 	 3
	 1 	 1503 	 0 	 651
	 2 	 334 	 0 	 293
	 3 	 530 	 0 	 556
Percent Accuracy: 53.245%
Testing Accuracy 0.532454098785

Fitting New Model
Model: bernoulli_bayes
Feature Matrix Info:
  Number of cases 15466
  Number of features 23534
Training percentage 0.75
Scoring used: accuracy
Regularization bounded between 10^(-2) and 10^(2):
Splitting data into training and testing...
Running Model Pipeline...
Fitting 3 folds for each of 8 candidates, totalling 24 fits
[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.7s
[Parallel(n_jobs=-1)]: Done  11 out of  24 | elapsed:    2.5s remaining:    3.0s
[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    4.8s finished
Fitting Complete!

best estimator: Pipeline(steps=[('feature_reduction', SelectFpr(alpha=1.0, score_func=<function chi2 at 0x2b42b12aa2a8>)), ('classifier', BernoulliNB(alpha=1.0, binarize=0.01, class_prior=None, fit_prior=True))])
best params: {'classifier__binarize': 0.01, 'feature_reduction__alpha': 1.0}
best score from that estimator: 0.62916282406
Label 0:
  NOT FOUND
  cir
  ed
  act
  ct
  fact
  district
  NOT FOUND
  case
  court
Total time: 7.97313308716
	 	 pred
true 	 	 1 	 3
	 1 	 3594 	 2057
	 3 	 1133 	 2975
Percent Accuracy: 67.312%
Training Accuracy 0.673122246132
	 	 pred
true 	 	 1 	 2 	 3
	 1 	 1345 	 0 	 809
	 2 	 252 	 0 	 375
	 3 	 403 	 0 	 683
Percent Accuracy: 52.444%
Testing Accuracy 0.524437548487

Fitting New Model
Model: logistic
Feature Matrix Info:
  Number of cases 15466
  Number of features 23534
Training percentage 0.75
Scoring used: accuracy
Regularization bounded between 10^(-2) and 10^(2):
Splitting data into training and testing...
Running Model Pipeline...
Fitting 3 folds for each of 20 candidates, totalling 60 fits
[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.7s
[Parallel(n_jobs=-1)]: Done  22 out of  60 | elapsed:    4.8s remaining:    8.2s
[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   13.7s finished
Fitting Complete!

best estimator: Pipeline(steps=[('feature_reduction', SelectFpr(alpha=0.6, score_func=<function chi2 at 0x2b42b12aa2a8>)), ('classifier', LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr',
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0))])
best params: {'classifier__C': 1, 'feature_reduction__alpha': 0.6}
best score from that estimator: 0.644840659904
Label 0:
  NOT FOUND
  berri
  date defend
  readi
  NOT FOUND
  consent
  properti subject
  murphi
  amend
  bona fide
Total time: 16.9117810726
	 	 pred
true 	 	 1 	 3
	 1 	 4698 	 953
	 3 	 1648 	 2460
Percent Accuracy: 73.348%
Training Accuracy 0.733476790655
	 	 pred
true 	 	 1 	 2 	 3
	 1 	 1812 	 0 	 342
	 2 	 459 	 0 	 168
	 3 	 713 	 0 	 373
Percent Accuracy: 56.504%
Testing Accuracy 0.565037496768

Fitting New Model
Model: svm
Feature Matrix Info:
  Number of cases 15466
  Number of features 23534
Training percentage 0.75
Scoring used: accuracy
Regularization bounded between 10^(-2) and 10^(2):
Splitting data into training and testing...
Running Model Pipeline...
Fitting 3 folds for each of 20 candidates, totalling 60 fits
[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.7s
[Parallel(n_jobs=-1)]: Done  22 out of  60 | elapsed:    5.1s remaining:    8.9s
[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   26.8s finished
Fitting Complete!

best estimator: Pipeline(steps=[('feature_reduction', SelectFpr(alpha=1.0, score_func=<function chi2 at 0x2b42b12aa2a8>)), ('classifier', LinearSVC(C=0.1, class_weight=None, dual=False, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,
     verbose=0))])
best params: {'classifier__C': 0.1, 'feature_reduction__alpha': 1.0}
best score from that estimator: 0.642996208628
Label 0:
  NOT FOUND
  NOT FOUND
  deduct
  decre
  award
  remedi
  new trial
  revers remand
  revers
  remand
Total time: 30.7367429733
	 	 pred
true 	 	 1 	 3
	 1 	 4907 	 744
	 3 	 1380 	 2728
Percent Accuracy: 78.235%
Training Accuracy 0.782354749462
	 	 pred
true 	 	 1 	 2 	 3
	 1 	 1817 	 0 	 337
	 2 	 465 	 0 	 162
	 3 	 725 	 0 	 361
Percent Accuracy: 56.323%
Testing Accuracy 0.563227307991
Stratified model results saved to /scratch/akp258/ml_results/model_results.pkl.20150510-213959.min_required_count.100.chi2.accuracy..csv
